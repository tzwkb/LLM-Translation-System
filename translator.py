#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMTS ç¿»è¯‘å·¥å…· - å·¥ç¨‹åŒ–ç‰ˆæœ¬
åŒè¯­å¹³è¡Œç¿»è¯‘å·¥å…·ï¼Œæ”¯æŒæœ¯è¯­åº“ã€æ–­ç‚¹ç»­ä¼ ã€è¯¦ç»†å¤„ç†è¿‡ç¨‹å±•ç¤º
"""

import os
import sys
import time
import pandas as pd
from typing import Optional, List, Dict, Any
from tqdm import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from config_manager import AppConfig
from file_manager import FileManager, FileSelector
from translation_engine import TranslationEngine, TerminologyEngine, ProcessingVisualizer
from checkpoint_manager import CheckpointManager

class TranslationOrchestrator:
    """ç¿»è¯‘åè°ƒå™¨ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.file_manager = FileManager(config.directories)
        self.file_selector = FileSelector(self.file_manager)
        self.translation_engine = TranslationEngine(config.translation)
        self.terminology_engine = None
        self.visualizer = ProcessingVisualizer(config.verbose)
        
    def setup_terminology(self, terminology_file: Optional[str]):
        """è®¾ç½®æœ¯è¯­åº“"""
        if terminology_file and os.path.exists(terminology_file):
            self.terminology_engine = TerminologyEngine(
                terminology_file, 
                self.config.directories.cache
            )
            stats = self.terminology_engine.get_stats()
            print(f"âœ… æœ¯è¯­åº“å·²åŠ è½½: {stats['total_terms']} æ¡æœ¯è¯­")
        else:
            self.terminology_engine = None
            print("âš ï¸ æœªä½¿ç”¨æœ¯è¯­åº“")
    
    def detect_languages(self, df: pd.DataFrame) -> tuple:
        """æ£€æµ‹æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€"""
        columns = df.columns.tolist()
        
        # ç®€å•çš„è¯­è¨€æ£€æµ‹é€»è¾‘
        source_lang, target_lang = "zh", "en"
        source_col, target_col = columns[0], columns[1]
        
        # æ ¹æ®åˆ—åæ¨æ–­è¯­è¨€
        if any(keyword in columns[0].lower() for keyword in ['chinese', 'zh', 'ä¸­æ–‡']):
            source_lang, target_lang = "zh", "en"
            source_col, target_col = columns[0], columns[1]
        elif any(keyword in columns[0].lower() for keyword in ['english', 'en']):
            source_lang, target_lang = "en", "zh"
            source_col, target_col = columns[1], columns[0]
        
        return source_lang, target_lang, source_col, target_col
    
    def process_translation(self, input_file: str, output_file: str, terminology_file: Optional[str] = None) -> str:
        """å¤„ç†ç¿»è¯‘ä»»åŠ¡"""
        print(f"\nğŸ“‚ è¾“å…¥æ–‡ä»¶: {self.file_manager.get_relative_path(input_file)}")
        print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {self.file_manager.get_relative_path(output_file)}")
        
        # è®¾ç½®æœ¯è¯­åº“
        self.setup_terminology(terminology_file)
        
        # è®¾ç½®æ£€æŸ¥ç‚¹ç®¡ç†å™¨
        checkpoint_manager = CheckpointManager(
            input_file, output_file, self.config.directories.cache
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æŸ¥ç‚¹
        checkpoint = None
        if checkpoint_manager.has_checkpoint():
            checkpoint_info = checkpoint_manager.get_resume_info(
                checkpoint_manager.load_checkpoint() or {}
            )
            print(f"\nğŸ”„ å‘ç°æ£€æŸ¥ç‚¹:")
            print(checkpoint_info)
            
            resume = input("æ˜¯å¦ä»æ£€æŸ¥ç‚¹ç»§ç»­? (y/n, é»˜è®¤y): ").strip().lower()
            if resume != 'n':
                checkpoint = checkpoint_manager.load_checkpoint()
        
        # åŠ è½½æ•°æ®
        if checkpoint:
            df = pd.DataFrame.from_dict(checkpoint['dataframe'])
            completed_indices = checkpoint['completed_indices']
            failed_indices = checkpoint.get('failed_indices', [])
            terminology_stats = checkpoint.get('statistics', {"total_replacements": 0})
            print(f"âœ… ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œå·²å®Œæˆ {len(completed_indices)} è¡Œ")
        else:
            df = pd.read_excel(input_file)
            completed_indices = []
            failed_indices = []
            terminology_stats = {"total_replacements": 0}
        
        # éªŒè¯æ•°æ®æ ¼å¼
        if df.shape[1] < 2:
            raise ValueError("Excelæ–‡ä»¶è‡³å°‘éœ€è¦ä¸¤åˆ—ï¼ˆæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ï¼‰")
        
        # æ£€æµ‹è¯­è¨€å’Œåˆ—
        source_lang, target_lang, source_col, target_col = self.detect_languages(df)
        print(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {source_lang} â†’ {target_lang}")
        print(f"ğŸ“‹ åˆ—æ˜ å°„: '{source_col}' â†’ '{target_col}'")
        
        # ç¡®å®šéœ€è¦ç¿»è¯‘çš„è¡Œ
        empty_mask = df[target_col].isna() | (df[target_col] == '') | (df[target_col] == 'nan')
        rows_to_translate = df.index[empty_mask].tolist()
        
        # æ’é™¤å·²å®Œæˆçš„è¡Œ
        rows_to_translate = [idx for idx in rows_to_translate if idx not in completed_indices]
        
        if not rows_to_translate:
            print("âœ… æ‰€æœ‰è¡Œéƒ½å·²ç¿»è¯‘å®Œæˆ")
            return output_file
        
        print(f"ğŸ“ éœ€è¦ç¿»è¯‘: {len(rows_to_translate)} è¡Œ")
        
        # å¼€å§‹ç¿»è¯‘
        return self._execute_translation(
            df, rows_to_translate, source_lang, target_lang, 
            source_col, target_col, output_file,
            checkpoint_manager, completed_indices, failed_indices, terminology_stats
        )
    
    def _execute_translation(self, df: pd.DataFrame, rows_to_translate: List[int],
                           source_lang: str, target_lang: str, source_col: str, target_col: str,
                           output_file: str, checkpoint_manager: CheckpointManager,
                           completed_indices: List[int], failed_indices: List[int],
                           terminology_stats: Dict[str, Any]) -> str:
        """æ‰§è¡Œç¿»è¯‘è¿‡ç¨‹"""
        
        total_rows = len(rows_to_translate)
        
        try:
            with tqdm(total=total_rows, desc="ç¿»è¯‘è¿›åº¦", unit="è¡Œ") as pbar:
                for i, idx in enumerate(rows_to_translate):
                    sentence_start_time = time.time()
                    self.visualizer.reset_counter()
                    
                    # è·å–åŸæ–‡
                    source_text = str(df.loc[idx, source_col]).strip()
                    if not source_text:
                        completed_indices.append(idx)
                        pbar.update(1)
                        continue
                    
                    self.visualizer.show_step("è¯»å–åŸæ–‡", source_text, f"è¡Œå·: {idx}")
                    
                    # æœ¯è¯­æ›¿æ¢
                    processed_text = source_text
                    replaced_terms = []
                    
                    if self.terminology_engine:
                        processed_text, replaced_terms = self.terminology_engine.replace_terms_in_text(
                            source_text, source_lang, target_lang
                        )
                        
                        if replaced_terms:
                            terminology_stats["total_replacements"] += len(replaced_terms)
                            self.visualizer.show_terminology_replacement(
                                source_text, processed_text, replaced_terms
                            )
                            
                            # ç®€åŒ–æ˜¾ç¤º
                            if not self.config.verbose:
                                print(f"æœ¯è¯­æ›¿æ¢ [{idx}]: {len(replaced_terms)} ä¸ª")
                    
                    # ç¿»è¯‘å¤„ç†
                    try:
                        if (self.terminology_engine and 
                            self.translation_engine.is_fully_translated(processed_text, source_lang)):
                            translated_text = processed_text
                            if not self.config.verbose:
                                print(f"å®Œå…¨åŒ¹é… [{idx}]: æ— éœ€APIç¿»è¯‘")
                        else:
                            translated_text = self.translation_engine.translate_text(
                                processed_text, source_lang, target_lang
                            )
                        
                        df.loc[idx, target_col] = translated_text
                        completed_indices.append(idx)
                        
                    except Exception as e:
                        error_msg = f"[ç¿»è¯‘å¤±è´¥: {str(e)[:50]}]"
                        df.loc[idx, target_col] = error_msg
                        failed_indices.append(idx)
                        if not self.config.verbose:
                            print(f"âŒ ç¿»è¯‘å¤±è´¥ [{idx}]: {str(e)[:100]}")
                    
                    # æ˜¾ç¤ºå¤„ç†æ€»ç»“
                    elapsed_time = time.time() - sentence_start_time
                    self.visualizer.show_sentence_summary(
                        idx, source_text, df.loc[idx, target_col], 
                        elapsed_time, len(replaced_terms)
                    )
                    
                    pbar.update(1)
                    
                    # è‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹
                    if (i + 1) % self.config.translation.auto_save_interval == 0:
                        checkpoint_manager.save_checkpoint(
                            idx, total_rows, df, completed_indices, failed_indices, terminology_stats
                        )
                        
                    # APIè°ƒç”¨å»¶è¿Ÿ
                    if replaced_terms and len(replaced_terms) == 0:  # åªæœ‰APIè°ƒç”¨æ—¶æ‰å»¶è¿Ÿ
                        time.sleep(self.config.translation.delay)
        
        except KeyboardInterrupt:
            print("\nâš ï¸ ç¿»è¯‘è¢«ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜è¿›åº¦...")
            checkpoint_manager.save_checkpoint(
                rows_to_translate[i] if i < len(rows_to_translate) else -1,
                total_rows, df, completed_indices, failed_indices, terminology_stats
            )
            print("ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯ä»¥ç»§ç»­ç¿»è¯‘")
            return output_file
        
        # ä¿å­˜ç»“æœ
        df.to_excel(output_file, index=False)
        
        # æ¸…ç†æ£€æŸ¥ç‚¹
        checkpoint_manager.cleanup_checkpoint()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        self._show_final_stats(completed_indices, failed_indices, terminology_stats)
        
        return output_file
    
    def _show_final_stats(self, completed: List[int], failed: List[int], terminology_stats: Dict[str, Any]):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*50}")
        print("ğŸ“Š ç¿»è¯‘å®Œæˆç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸç¿»è¯‘: {len(completed)} è¡Œ")
        print(f"  âŒ ç¿»è¯‘å¤±è´¥: {len(failed)} è¡Œ")
        print(f"  ğŸ”„ æœ¯è¯­æ›¿æ¢: {terminology_stats.get('total_replacements', 0)} æ¬¡")
        
        if self.terminology_engine:
            stats = self.terminology_engine.get_stats()
            print(f"  ğŸ“š æœ¯è¯­åº“: {stats['total_terms']} æ¡æœ¯è¯­")
        
        print(f"{'='*50}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ LLMTS ç¿»è¯‘å·¥å…· - å·¥ç¨‹åŒ–ç‰ˆæœ¬")
    print("="*50)
    
    # åˆå§‹åŒ–é…ç½®
    config = AppConfig.create_default()
    config.setup()
    
    # åˆ›å»ºç¿»è¯‘åè°ƒå™¨
    orchestrator = TranslationOrchestrator(config)
    
    # æ¸…ç†è¿‡æœŸç¼“å­˜
    cleaned = orchestrator.file_manager.cleanup_cache()
    if cleaned > 0:
        print(f"ğŸ—‘ï¸ æ¸…ç†äº† {cleaned} ä¸ªè¿‡æœŸç¼“å­˜æ–‡ä»¶")
    
    # é€‰æ‹©è¾“å…¥æ–‡ä»¶
    input_file = orchestrator.file_selector.select_input_file()
    if not input_file:
        return
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = orchestrator.file_manager.generate_output_path(input_file)
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {orchestrator.file_manager.get_relative_path(output_file)}")
    
    # é€‰æ‹©æœ¯è¯­åº“
    terminology_file = orchestrator.file_selector.select_terminology_file()
    if terminology_file:
        print(f"ğŸ“š æœ¯è¯­åº“: {orchestrator.file_manager.get_relative_path(terminology_file)}")
    
    # è¯¢é—®æ˜¯å¦å¯ç”¨è¯¦ç»†æ¨¡å¼
    verbose_choice = input("æ˜¯å¦å¯ç”¨è¯¦ç»†å¤„ç†è¿‡ç¨‹æ˜¾ç¤º? (y/n, é»˜è®¤n): ").strip().lower()
    config.verbose = (verbose_choice == 'y')
    orchestrator.visualizer.verbose = config.verbose
    
    if config.verbose:
        print("âœ… å·²å¯ç”¨è¯¦ç»†æ¨¡å¼")
    
    # å¼€å§‹ç¿»è¯‘
    print("\n" + "="*50)
    print("ğŸš€ å¼€å§‹ç¿»è¯‘...")
    
    try:
        result_file = orchestrator.process_translation(input_file, output_file, terminology_file)
        print(f"\nğŸ‰ ç¿»è¯‘å®Œæˆ!")
        print(f"ğŸ“‚ ç»“æœæ–‡ä»¶: {orchestrator.file_manager.get_relative_path(result_file)}")
        
    except Exception as e:
        print(f"\nâŒ ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
