#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¿»è¯‘å¼•æ“æ¨¡å—
"""

import time
import pandas as pd
from openai import OpenAI
from typing import Dict, List, Tuple, Optional, Any
from config_manager import TranslationConfig
import re

class TranslationEngine:
    """ç¿»è¯‘å¼•æ“"""
    
    def __init__(self, config: TranslationConfig):
        self.config = config
        self.client = OpenAI(api_key=config.api_key, base_url=config.base_url)
    
    def translate_text(self, text: str, source_lang: str = "zh", target_lang: str = "en") -> str:
        """ç¿»è¯‘å•ä¸ªæ–‡æœ¬"""
        for attempt in range(self.config.max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.config.model,
                    messages=[{
                        "role": "user", 
                        "content": f"è¯·å°†ä»¥ä¸‹{source_lang}æ–‡æœ¬ç¿»è¯‘æˆ{target_lang}ï¼Œåªè¿”å›è¯‘æ–‡ï¼Œä¸è¦è§£é‡Šï¼š\n{text}"
                    }],
                    temperature=0.3
                )
                
                result = self._extract_response_content(response)
                if result and not self._is_html_response(result):
                    return result
                    
            except Exception as e:
                if attempt == self.config.max_retries - 1:
                    raise e
                time.sleep(self.config.delay * (attempt + 1))
        
        return f"[ç¿»è¯‘å¤±è´¥: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°]"
    
    def _extract_response_content(self, response) -> str:
        """æå–APIå“åº”å†…å®¹"""
        if hasattr(response, 'choices') and response.choices:
            return response.choices[0].message.content.strip()
        elif isinstance(response, str):
            return response.strip()
        elif isinstance(response, dict):
            if 'choices' in response and response['choices']:
                return response['choices'][0]['message']['content'].strip()
            elif 'content' in response:
                return response['content'].strip()
        return str(response)
    
    def _is_html_response(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºHTMLå“åº”"""
        return text.lower().startswith(('<!doctype html>', '<html'))
    
    def is_fully_translated(self, text: str, source_lang: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦å·²å®Œå…¨ç¿»è¯‘"""
        if source_lang == "zh":
            return not bool(re.search(r'[\u4e00-\u9fff]', text))
        return False

class TerminologyEngine:
    """æœ¯è¯­å¼•æ“"""
    
    def __init__(self, terminology_file: Optional[str] = None, cache_dir: str = "cache"):
        self.terminology_dict = {}
        self.reverse_dict = {}
        self.replacement_cache = {}
        self.sorted_terms_cache = {}
        self.cache_dir = cache_dir
        
        if terminology_file:
            self.load_terminology(terminology_file)
    
    def load_terminology(self, file_path: str):
        """åŠ è½½æœ¯è¯­åº“ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        import os
        import pickle
        import hashlib
        
        # ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„
        file_hash = hashlib.md5(file_path.encode()).hexdigest()[:8]
        cache_file = os.path.join(self.cache_dir, f"terminology_{file_hash}.pkl")
        
        # æ£€æŸ¥ç¼“å­˜
        if os.path.exists(cache_file):
            try:
                cache_mtime = os.path.getmtime(cache_file)
                file_mtime = os.path.getmtime(file_path)
                if cache_mtime > file_mtime:
                    with open(cache_file, 'rb') as f:
                        cached_data = pickle.load(f)
                        self.terminology_dict = cached_data['terminology_dict']
                        self.reverse_dict = cached_data['reverse_dict']
                        self.sorted_terms_cache = cached_data['sorted_terms_cache']
                    return
            except (OSError, pickle.PickleError):
                pass
        
        # åŠ è½½æœ¯è¯­åº“
        df = pd.read_excel(file_path)
        if df.shape[1] < 2:
            raise ValueError("æœ¯è¯­åº“æ–‡ä»¶è‡³å°‘éœ€è¦ä¸¤åˆ—")
        
        chinese_col, english_col = df.columns[0], df.columns[1]
        
        # æ‰¹é‡å¤„ç†
        valid_mask = (
            df[chinese_col].notna() & df[english_col].notna() &
            (df[chinese_col] != '') & (df[english_col] != '') &
            (df[chinese_col] != 'nan') & (df[english_col] != 'nan')
        )
        
        valid_df = df[valid_mask]
        self.terminology_dict = dict(zip(
            valid_df[chinese_col].astype(str).str.strip(),
            valid_df[english_col].astype(str).str.strip()
        ))
        
        self.reverse_dict = {v: k for k, v in self.terminology_dict.items()}
        
        # é¢„è®¡ç®—æ’åºç¼“å­˜
        self._update_sorted_cache()
        
        # ä¿å­˜ç¼“å­˜
        try:
            os.makedirs(self.cache_dir, exist_ok=True)
            with open(cache_file, 'wb') as f:
                pickle.dump({
                    'terminology_dict': self.terminology_dict,
                    'reverse_dict': self.reverse_dict,
                    'sorted_terms_cache': self.sorted_terms_cache
                }, f)
        except (OSError, pickle.PickleError):
            pass
    
    def _update_sorted_cache(self):
        """æ›´æ–°æ’åºç¼“å­˜"""
        for direction in ['zh_to_en', 'en_to_zh']:
            source_dict = self.terminology_dict if direction == 'zh_to_en' else self.reverse_dict
            self.sorted_terms_cache[direction] = sorted(
                source_dict.keys(), key=len, reverse=True
            )
    
    def replace_terms_in_text(self, text: str, source_lang: str, target_lang: str) -> Tuple[str, List[str]]:
        """æ›¿æ¢æ–‡æœ¬ä¸­çš„æœ¯è¯­ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not self.terminology_dict:
            return text, []
        
        # ä½¿ç”¨ç¼“å­˜
        cache_key = (text, source_lang, target_lang)
        if cache_key in self.replacement_cache:
            return self.replacement_cache[cache_key]
        
        # ç¡®å®šæ›¿æ¢æ–¹å‘
        direction = 'zh_to_en' if source_lang == 'zh' and target_lang == 'en' else 'en_to_zh'
        source_dict = self.terminology_dict if direction == 'zh_to_en' else self.reverse_dict
        
        if direction not in self.sorted_terms_cache:
            self._update_sorted_cache()
        
        replaced_terms = []
        result_text = text
        
        # æŒ‰é•¿åº¦æ’åºæ›¿æ¢ï¼ˆé¿å…çŸ­è¯ä¼˜å…ˆåŒ¹é…ï¼‰
        for term in self.sorted_terms_cache[direction]:
            if term in source_dict:
                target_term = source_dict[term]
                # ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…
                pattern = r'\b' + re.escape(term) + r'\b'
                if re.search(pattern, result_text):
                    result_text = re.sub(pattern, target_term, result_text)
                    replaced_terms.append(f"{term} -> {target_term}")
        
        # ç¼“å­˜ç»“æœ
        result = (result_text, replaced_terms)
        self.replacement_cache[cache_key] = result
        
        return result
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœ¯è¯­åº“ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_terms": len(self.terminology_dict),
            "chinese_to_english": len(self.terminology_dict),
            "english_to_chinese": len(self.reverse_dict),
            "cache_hits": len(self.replacement_cache),
            "sorted_cache": len(self.sorted_terms_cache)
        }

class ProcessingVisualizer:
    """å¤„ç†è¿‡ç¨‹å¯è§†åŒ–å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.step_counter = 0
    
    def show_step(self, step_name: str, content: str = "", details: str = ""):
        """æ˜¾ç¤ºå¤„ç†æ­¥éª¤"""
        if not self.verbose:
            return
        self.step_counter += 1
        print(f"\n{'='*50}")
        print(f"ğŸ“ æ­¥éª¤ {self.step_counter}: {step_name}")
        if content:
            print(f"ğŸ“„ {content}")
        if details:
            print(f"ğŸ” {details}")
    
    def show_terminology_replacement(self, original: str, processed: str, terms: List[str]):
        """æ˜¾ç¤ºæœ¯è¯­æ›¿æ¢"""
        if not self.verbose or not terms:
            return
        print(f"\nğŸ”„ æœ¯è¯­æ›¿æ¢ ({len(terms)} ä¸ª):")
        for term in terms[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  â€¢ {term}")
        if len(terms) > 3:
            print(f"  ... è¿˜æœ‰ {len(terms) - 3} ä¸ª")
    
    def show_sentence_summary(self, idx: int, original: str, final: str, elapsed_time: float, term_count: int):
        """æ˜¾ç¤ºå¥å­å¤„ç†æ€»ç»“"""
        if not self.verbose:
            return
        print(f"\nğŸ“‹ å¤„ç†å®Œæˆ [è¡Œ{idx}] - {elapsed_time:.2f}s")
        if term_count > 0:
            print(f"   æœ¯è¯­æ›¿æ¢: {term_count} ä¸ª")
        print(f"   åŸæ–‡: {original[:30]}{'...' if len(original) > 30 else ''}")
        print(f"   è¯‘æ–‡: {final[:30]}{'...' if len(final) > 30 else ''}")
    
    def reset_counter(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.step_counter = 0
